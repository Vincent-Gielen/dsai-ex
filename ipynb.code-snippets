{
	// Place your global snippets here. Each snippet is defined under a snippet name and has a scope, prefix, body and 
	// description. Add comma separated ids of the languages where the snippet is applicable in the scope field. If scope 
	// is left empty or omitted, the snippet gets applied to all languages. The prefix is what is 
	// used to trigger the snippet and the body will be expanded and inserted. Possible variables are: 
	// $1, $2 for tab stops, $0 for the final cursor position, and ${1:label}, ${2:another} for placeholders. 
	// Placeholders with the same ids are connected.
	// Example:
	// "Print to console": {
	// 	"scope": "javascript,typescript",
	// 	"prefix": "log",
	// 	"body": [
	// 		"console.log('$1');",
	// 		"$2"
	// 	],
	// 	"description": "Log output to console"
	// }

	"imports": {
  "prefix": "imports",
  "body": [
    "# Package imports",
    "# Package imports for data science",
    "import numpy as np",
    "import pandas as pd",
    "import scipy.stats as stats",
    "from pandas.api.types import CategoricalDtype",
    "import matplotlib.pyplot as plt",
    "import seaborn as sns",
    "import math",
    "from statsmodels.graphics.mosaicplot import mosaic",
    "",
    "# Package imports for time series analysis",
    "from datetime import datetime",
    "from statsmodels.tsa.holtwinters import SimpleExpSmoothing",
    "from statsmodels.tsa.holtwinters import Holt",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing",
    "from statsmodels.tsa.seasonal import seasonal_decompose",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error"
  ],
  "description": "Standard data science + time series imports"
},
  "catplot": {
    "prefix": "catplot",
    "body": [
      "# Bar chart in Seaborn: catplot() with 'kind = \"count\". you can play around with x, y and hue",
      "sns.catplot(data = x, kind = \"count\", y = value);"
    ],
  },
  "barchart":{
    "prefix": "barchart",
    "body": [
      "# Bar chart with error bar",
      "sns.barplot(data=tips, x='sex', y='tip', errorbar='sd');",
    ],
  "description": "Bar chart in with error bars"
  },
    "Contingency Table Horizontal Stacked Bar Chart": {
    "prefix": "contingency_barh",
    "body": [
      "# --- Create a contingency table ---",
      "observed = pd.crosstab(${1:data}[$2:row_variable], ${1:data}[$3:column_variable]) # hier eventueel ,normalize='index' om gelijk te maken",
      "",
      "# --- Plot: Horizontally oriented stacked bar chart ---",
      "observed.plot(kind='barh', stacked=True)",
      "volledig optional onderaan",
      "plt.xlabel('${4:X-axis label}')  # optional: change axis labels",
      "plt.ylabel('${5:Y-axis label}')",
      "plt.title('${6:Title}')",
      "plt.legend(title='${7:Legend title}')",
      "plt.tight_layout()",
      "plt.show()"
    ],
    "description": "Create and plot a stacked horizontal bar chart from a contingency table"
  },
  "boxplot":{
    "prefix": "boxplot",
    "body": [
      "# Visualisation using a box plot (Seaborn)",
      "sns.boxplot(data=df, x=value); #of hue=column, if you want to color by a column",
    ],
    "description": "Box plot using Seaborn"
  }
  ,
  "Mosaic Plot with Colormap": {
  "prefix": "mosaic_colormap",
  "body": [
    "# --- Define the colormap ---",
    "${1:colormap_name} = mpl.colormaps['${2:plasma}']  # Choose a colormap (e.g., plasma, viridis, coolwarm)",
    "",
    "# --- Define the color mapping function ---",
    "props = lambda key: {'color': ${1:colormap_name}(int(key[1]) / ${3:5})}  # Adjust denominator if range differs",
    "",
    "# --- Create the mosaic plot ---",
    "mosaic(",
    "    data=${4:dataframe}.sort_values(by=['${5:column_variable}']),",
    "    index=['${6:row_variable}', '${5:column_variable}'],",
    "    gap=${7:0.05},",
    "    properties=props",
    ")",
    "plt.title('${8:Mosaic Plot Title}')",
    "plt.tight_layout()",
    "plt.show()"
  ],
  "description": "Create a colored mosaic plot using a specified colormap and variable mapping"
  }
  ,
  "countplot": {
    "prefix": "countplot",
    "body": [
      "# Count plot using Seaborn",
      "sns.countplot(data=df, y=column);",
      "# If you want order : order=ais.sport.value_counts().index, something like that",
    ],
    "description": "Count plot using Seaborn"
  },
  "histogram": {
    "prefix": "histogram",
    "body": [
      "# Histogram using Seaborn",
      "sns.displot(x=df, bins=30);"
    ],
    "description": "Histogram using Seaborn"
  }
  ,
    "kdeplot": {
      "prefix": "kdeplot",
      "body": [
        "# Kernel Density Estimate plot using Seaborn",
        "sns.kdeplot(data=df, x='random', hue='random');"
      ],
      "description": "KDE plot using Seaborn"
    }
    ,
    "histogram+kde": {
      "prefix": "histkde",
      "body": [
        "# Histogram with KDE using Seaborn",
        "sns.displot(x=df, bins=30, kde=True);"
      ],
      "description": "Histogram with KDE using Seaborn"
    },

    "violinplot": {
      "prefix": "violinplot",
      "body": [
      "# Violin plot using Seaborn",
      "sns.violinplot(data=df, x=column);"
      ],
      "description": "Violin plot using Seaborn"
    },
    "statistics": {
      "prefix": "statistics",
      "body": [
        "# Centrality and dispersion measures",
        "# Mean, standard deviation & friends",
        "print(f\"Mean:                {${1:data}['${2:column}'].mean()}\")",
        "print(f\"Standard deviation:  {${1:data}['${2:column}'].std()}\") # Pay attention: n-1 in the denominator",
        "print(f\"Variance:            {${1:data}['${2:column}'].var()}\") # Pay attention: n-1 in the denominator",
        "print(f\"Skewness:            {${1:data}['${2:column}'].skew()}\")",
        "print(f\"Kurtosis:            {${1:data}['${2:column}'].kurtosis()}\")",
        "print(f\"Minimum:             {${1:data}['${2:column}'].min()}\")",
        "print(f\"Median:              {${1:data}['${2:column}'].median()}\")",
        "print(f\"Maximum:             {${1:data}['${2:column}'].max()}\")",
        "percentiles = [0.0, 0.25, 0.5, 0.75, 1.0]",
        "print(\"Percentiles\", percentiles, \"\\n\", ${1:data}['${2:column}'].quantile(percentiles))",
        "print(\"Inter Quartile Range:\", ${1:data}['${2:column}'].quantile(.75) - ${1:data}['${2:column}'].quantile(.25))",
        "print(f\"Range :              {${1:data}['${2:column}'].max() - ${1:data}['${2:column}'].min()}\")"
        ],
        "description": "Print mean, std, variance, skewness, kurtosis, median & co for a column"
    },
    "Seaborn Lineplot": {
      "prefix": "lineplot",
      "body": [
        "sns.lineplot(x='${1:x-axis}', y='${2:y-axis}', data=${3:data}, color='${4:color}', label='${5:label}')",
        "# ax: axes (als je meer plot) | x: x-axis col | y: y-axis col | data: source | color: line color | label: legend label"
      ],
      "description": "Insert a single sns.lineplot statement"
    },
  "Probability of winning at least one  (P_A_or_B)": {
    "prefix": "prob_either",
    "body": [
      "# Given probabilities",
      "P_A = 0.6",
      "P_B = 0.4",
      "P_A_and_B = 0.35",
      "# Calculate P(A ∪ B)",
      "P_A_or_B = P_A + P_B - P_A_and_B",
      "print(f\"3. Probability of winning at least one  (P_A_or_B) = {P_A_or_B:.2f}\")"
    ],
    "description": "Calculate and print probability of winning at least one "
  },

  "Probability of winning neither  (P_neither)": {
    "prefix": "prob_neither",
    "body": [
      "# Given probabilities",
      "P_A = 0.6",
      "P_B = 0.4",
      "P_A_and_B = 0.35",
      "# Calculate P(not A and not B) = 1 - P(A ∪ B)",
      "P_A_or_B = P_A + P_B - P_A_and_B",
      "P_neither = 1 - P_A_or_B",
      "print(f\"4. Probability of winning neither  (P_neither) = {P_neither:.2f}\")"
    ],
    "description": "Calculate and print probability of winning neither "
  },

  "Probability sample mean less than x_bar": {
    "prefix": "clt_prob",
    "body": [
      "# Parameters",
      "mu = ${1:}         # population mean",
      "sigma = ${2:}      # population standard deviation",
      "n = ${3:}          # sample size",
      "x_bar = ${4:}      # value to check probability for",
      "",
      "# Step 1: Compute Standard Error (SE)",
      "SE = sigma / math.sqrt(n)",
      "",
      "# Step 2: Compute z-score",
      "z = (x_bar - mu) / SE",
      "",
      "# Step 3: Compute probability P(X̄ < x_bar)",
      "p_value = stats.norm.cdf(z)",
      "",
      "# Step 3.1: Compute probability P(X̄ < x_bar) - geen z-score",
      "p_value = stats.norm.cdf(x, loc=mu, scale=SE) # x is probabiliteit dat de average mu kleiner < is dan x ",
      "# je kan ook probabiliteit groter dan krijgen door 1 - p_value",
      "",
      "# Output result",
      "print(f\"Standard Error: {SE:.4f}\")",
      "print(f\"Z-score: {z:.4f}\")",
      "print(f\"Probability the sample mean is less than {x_bar}: {p_value:.4f} ({p_value*100:.2f}%)\")"
    ],
    "description": "Probability that sample mean is less than x_bar (normal approx.) - Calculate probability sample mean is less than a value using the Central Limit Theorem"
  },

  "Confidence Interval for Mean (Normal)": {
    "prefix": "confint_z",
    "body": [
      "# Confidence interval for the mean (Normal distribution, known or large n)",
      "alpha = ${1:0.05}  # alpha / significance level, 1-alpha is the confidence level, pas deze aan naar 0.01 voor 99% CI",
      "m = ${2:sample_mean}  # sample mean",
      "s = ${3:sample_std}   # sample standard deviation",
      "n = ${4:sample_size}  # sample size",
      "",
      "# Calculate confidence interval",
      "ci_low, ci_high = stats.norm.interval(1-alpha, loc=m, scale=s/np.sqrt(n))",
      "print(f\"{int((1-alpha)*100)}% Confidence interval: [{ci_low:.4f}, {ci_high:.4f}]\")"
    ],
    "description": "Calculate confidence interval for the mean using stats.norm.interval"
  },
  "Confidence Interval for Mean (t-distribution)": {
    "prefix": "confint_t",
    "body": [
      "# Confidence interval for the mean (t-distribution, small sample or unknown population std)",
      "alpha = ${1:0.05}  # significance level",
      "m = ${2:sample_mean}  # sample mean",
      "s = ${3:sample_std}   # sample standard deviation",
      "n = ${4:sample_size}  # sample size",
      "",
      "# Calculate confidence interval using t-distribution",
      "ci_low, ci_high = stats.t.interval(1-alpha, df=n-1, loc=m, scale=s/np.sqrt(n))",
      "print(f\"{int((1-alpha)*100)}% Confidence interval (t): [{ci_low:.4f}, {ci_high:.4f}]\")",
      "",
      // "# --- t-distribution functions for this CI ---",
      // "# Probability density at the lower CI bound",
      // "pdf_low = stats.t.pdf((ci_low-m)/(s/np.sqrt(n)), df=n-1)",
      // "# Left-tail probability at lower CI bound",
      // "cdf_low = stats.t.cdf((ci_low-m)/(s/np.sqrt(n)), df=n-1)",
      // "# Right-tail probability at upper CI bound",
      // "sf_high = stats.t.sf((ci_high-m)/(s/np.sqrt(n)), df=n-1)",
      // "print(f\"PDF at lower CI bound: {pdf_low:.4f}\")",
      // "print(f\"CDF at lower CI bound: {cdf_low:.4f}\")",
      // "print(f\"SF at upper CI bound: {sf_high:.4f}\")"
    ],
    "description": "Calculate confidence interval for the mean using stats.t.interval (for small samples) and show t-distribution functions at CI bounds"
  },
  "Right-Tailed Z-Test Plot": {
  "prefix": "ztest_right_tail_plot",
  "body": [
    "# Properties of the sample:",
    "n = ${1:sample_size}                # Sample size",
    "mu_0 = ${2:null_mean}              # Null hypothesis mean (H₀)",
    "sigma = ${3:population_std}        # Population standard deviation (known)",
    "x_bar = ${4:sample_mean}           # Observed sample mean",
    "SE = sigma / math.sqrt(n)          # Standard Error",
    "",
    "# Generate sampling distribution under H₀, H3_03",
    "dist_x = np.linspace(mu_0 - 4 * SE, mu_0 + 4 * SE, 201)",
    "dist_y = stats.norm.pdf(dist_x, loc=mu_0, scale=SE)",
    "",
    "# Plot normal curve",
    "plt.plot(dist_x, dist_y, label='Sampling Distribution under $H_0$')",
    "",
    "# Shade the right-tail (p-value area)",
    "plt.fill_between(dist_x, 0, dist_y, where=(dist_x >= x_bar), color='lightblue', alpha=0.5, label='p-value area')",
    "",
    "# Sample mean line",
    "plt.axvline(x_bar, color='blue', linestyle='--', label='Sample Mean')",
    "",
    "# Null hypothesis mean line",
    "plt.axvline(mu_0, color='black', linestyle=':', label='Null Mean')",
    "",
    "# Labels and title",
    "plt.title('Right-Tailed Z-Test')",
    "plt.xlabel('Sample Mean')",
    "plt.ylabel('Probability Density')",
    "plt.legend()",
    "plt.grid(True)",
    "plt.show()",
    "",
    "# Calculate p-value",
    "alpha = 0.05  # Significance level chosen by the researcher",
    "p = stats.norm.sf(x_bar, loc=mu_0, scale=sigma/np.sqrt(n))",
    "",
    "print(f\"p-value: {p:.5f}\")",
    "if p < alpha:",
    "    print(\"p < alpha: reject H0\")",
    "else:",
    "    print(\"p > alpha: do not reject H0\")",
    "",
    "#Alternative: Calculate critical value (g) and compare sample mean",
    "g = stats.norm.isf(alpha, loc=mu_0, scale=sigma / np.sqrt(n))",
    "print(\"Critical value g ≃ %.3f\" % g)",
    "if x_bar < g:",
    "    print(\"sample mean = %.3f < g = %.3f: do not reject H0\" % (x_bar, g))",
    "else:",
    "    print(\"sample mean = %.3f > g = %.3f: reject H0\" % (x_bar, g))",
  ],
  "description": "Visualize the sampling distribution and p-value for a right-tailed Z-test"
  },
  "Right-Tailed Z-Test Visualization (Critical Value)": {
  "prefix": "ztest_right_tail_plot_crit",
  "body": [
    "# Parameters",
    "mu = ${1:population_mean}           # population mean under H₀",
    "sigma = ${2:population_std}         # population standard deviation (known)",
    "n = ${3:sample_size}                # sample size",
    "m_sample = ${4:sample_mean}         # sample mean",
    "alpha = ${5:0.05}                   # significance level",
    "",
    "# Critical value for right-tailed test",
    "g = stats.norm.isf(alpha, loc=mu, scale=sigma / np.sqrt(n))",
    "print(\"Critical value g ≃ %.3f\" % g)",
    "if x_bar < g:",
    "    print(\"sample mean = %.3f < g = %.3f: do not reject H0\" % (x_bar, g))",
    "else:",
    "    print(\"sample mean = %.3f > g = %.3f: reject H0\" % (x_bar, g))",
    "",
    "# X and Y values for Gauss curve",
    "dist_x = np.linspace(mu - 4 * sigma/np.sqrt(n), mu + 4 * sigma/np.sqrt(n), num=201)",
    "dist_y = stats.norm.pdf(dist_x, mu, sigma/np.sqrt(n))",
    "",
    "# Plot the normal distribution",
    "fig, dplot = plt.subplots(1, 1)",
    "dplot.plot(dist_x, dist_y)",
    "",
    "# Mean under H₀",
    "dplot.axvline(mu, color='orange', lw=2, label='Population Mean (H₀)')",
    "",
    "# Sample mean",
    "dplot.axvline(m_sample, color='red', label='Sample Mean')",
    "",
    "# Fill acceptance region",
    "dplot.fill_between(dist_x, 0, dist_y, where=dist_x <= g, color='lightblue', label='Acceptance Region')",
    "",
    "# Add legend and title",
    "dplot.legend()",
    "dplot.set_title('Right-Tailed Z-Test (Critical Value Method)')",
    "plt.xlabel('Sample Mean Values')",
    "plt.ylabel('Probability Density')",
    "plt.show()"
  ],
  "description": "Right-tailed Z-test visualization using the critical value approach with shaded acceptance region and sample mean"
  },
  "Left-Tailed Z-Test (p-value method)": {
    "prefix": "ztest_left_tail_plot",
    "body": [
      "# Parameters",
      "n = ${1:sample_size}               # Sample size",
      "mu_0 = ${2:null_mean}             # Null hypothesis mean (H₀)",
      "sigma = ${3:population_std}       # Known population standard deviation",
      "x_bar = ${4:sample_mean}          # Sample mean",
      "alpha = ${5:0.05}                 # Significance level",
      "# Standard Error",
      "SE = sigma / math.sqrt(n)",
      "",
      "# Compute p-value (left-tailed => use CDF)",
      "p = stats.norm.cdf(x_bar, loc=mu_0, scale=SE)",
      "print(f\"p-value: {p:.5f}\")",
      "if p < alpha:",
      "    print(\"p < alpha, reject H₀\")",
      "else:",
      "    print(\"p >= alpha, do not reject H₀\")",
      "# --- PLOT THE DISTRIBUTION ---",
      "# X-values for curve",
      "dist_x = np.linspace(mu_0 - 4 * SE, mu_0 + 4 * SE, 201)",
      "# Y-values for normal curve",
      "dist_y = stats.norm.pdf(dist_x, loc=mu_0, scale=SE)",
      "plt.plot(dist_x, dist_y, label='Sampling Distribution under $H_0$')",
      "",
      "# Shade the left-tail (p-value area)",
      "plt.fill_between(dist_x, 0, dist_y, where=(dist_x <= x_bar), color='lightblue', alpha=0.5, label='p-value area')",
      "",
      "# Sample mean line",
      "plt.axvline(x_bar, color='blue', linestyle='--', label='Sample Mean')",
      "# Null hypothesis mean line",
      "plt.axvline(mu_0, color='black', linestyle=':', label='Null Mean')",
      "",
      "# Labels and title",
      "plt.title('Left-Tailed Z-Test')",
      "plt.xlabel('Sample Mean')",
      "plt.ylabel('Probability Density')",
      "plt.legend()",
      "plt.grid(True)",
      "plt.show()"
    ],
    "description": "Left-tailed Z-test (with plot) using p-value method (CLT, population std known)"
  },
  "Left-Tailed Z-Test (critical value method + plot)": {
  "prefix": "ztest_left_tail_plot_crit",
  "body": [
    "# Parameters",
    "n = ${1:sample_size}",
    "mu = ${2:population_mean}",
    "sigma = ${3:population_std}",
    "m_sample = ${4:sample_mean}",
    "alpha = ${5:0.05}",
    "",
    "# Compute critical value (left-tailed test)",
    "g = stats.norm.isf(1 - alpha, loc=mu, scale=sigma / np.sqrt(n))",
    "print(f\"Critical value g ≃ {g:.3f}\")",
    "if m_sample > g:",
    "    print(f\"sample mean = {m_sample:.3f} > g = {g:.3f}: do not reject H₀\")",
    "else:",
    "    print(f\"sample mean = {m_sample:.3f} < g = {g:.3f}: reject H₀\")",
    "",
    "# Gauss curve",
    "dist_x = np.linspace(mu - 4 * sigma/np.sqrt(n), mu + 4 * sigma/np.sqrt(n), num=201)",
    "dist_y = stats.norm.pdf(dist_x, mu, sigma/np.sqrt(n))",
    "fig, dplot = plt.subplots(1, 1)",
    "dplot.plot(dist_x, dist_y)",
    "dplot.axvline(mu, color='orange', lw=2, label='Population Mean (H₀)')",
    "dplot.axvline(m_sample, color='red', label='Sample Mean')",
    "dplot.fill_between(dist_x, 0, dist_y, where=dist_x >= g, color='lightblue', label='Acceptance Region')",
    "dplot.legend()",
    "dplot.set_title('Left-Tailed Z-Test (Critical Value Method)')",
    "plt.xlabel('Sample Mean Values')",
    "plt.ylabel('Probability Density')",
    "plt.show()"
  ],
  "description": "Left-tailed Z-test using critical value method with normal curve plot"
  },
  "Two-Tailed Z-Test Plot": {
  "prefix": "ztest_two_tail_plot",
  "body": [
    "# --- Parameters ---",
    "n = ${1:sample_size}              # Sample size",
    "mu_0 = ${2:null_mean}            # Null hypothesis mean (H₀)",
    "sigma = ${3:population_std}      # Known population standard deviation",
    "x_bar = ${4:sample_mean}         # Sample mean",
    "alpha = ${5:0.05}                # Significance level",
    "",
    "# --- Standard Error ---",
    "SE = sigma / math.sqrt(n)",
    "",
    "# --- P-VALUE METHOD (Two-Tailed) ---",
    "# Use survival function for one side, multiply by 2",
    "p = 2 * stats.norm.sf(abs(x_bar - mu_0), loc=0, scale=SE)",
    "print(f\"Two-tailed p-value: {p:.5f}\")",
    "if p < alpha:",
    "    print(\"p < alpha: reject H₀\")",
    "else:",
    "    print(\"p ≥ alpha: do not reject H₀\")",
    "",
    "# --- CRITICAL VALUES METHOD ---",
    "# Two critical values: g1 (left) and g2 (right)",
    "g1 = mu_0 - stats.norm.isf(alpha/2) * SE",
    "g2 = mu_0 + stats.norm.isf(alpha/2) * SE",
    "print(f\"Acceptance region [g1, g2] ≃ [{g1:.3f}, {g2:.3f}]\")",
    "if g1 < x_bar < g2:",
    "    print(f\"x̄ = {x_bar:.3f} is inside acceptance region: do not reject H₀\")",
    "else:",
    "    print(f\"x̄ = {x_bar:.3f} is outside acceptance region: reject H₀\")",
    "",
    "# --- PLOT SAMPLING DISTRIBUTION ---",
    "dist_x = np.linspace(mu_0 - 4 * SE, mu_0 + 4 * SE, 201)",
    "dist_y = stats.norm.pdf(dist_x, loc=mu_0, scale=SE)",
    "plt.plot(dist_x, dist_y, label='Sampling Distribution under $H_0$')",
    "",
    "# Plot vertical lines for sample mean and mu_0",
    "plt.axvline(mu_0, color='orange', lw=2, linestyle='-', label='Null Mean')",
    "plt.axvline(x_bar, color='red', lw=2, linestyle='--', label='Sample Mean')",
    "",
    "# Fill acceptance region between g1 and g2",
    "acc_x = np.linspace(g1, g2, 101)",
    "acc_y = stats.norm.pdf(acc_x, loc=mu_0, scale=SE)",
    "plt.fill_between(acc_x, 0, acc_y, color='lightblue', alpha=0.5, label='Acceptance Region')",
    "",
    "# Labels, legend, and show plot",
    "plt.title('Two-Tailed Z-Test')",
    "plt.xlabel('Sample Mean')",
    "plt.ylabel('Probability Density')",
    "plt.legend()",
    "plt.grid(True)",
    "plt.show()"
  ],
  "description": "Two-tailed z-test (with plot): calculates p-value and critical values, plots acceptance region and highlights conclusion."
},
"Right-Tailed Student's t-Test Plot": {
  "prefix": "ttest_right_tail_plot",
  "body": [
    "# --- Parameters ---",
    "# scores = ${1:[6, 3, 6, 7, 6, 10, 6, 8, 7, 9, 3, 6, 4, 6, 8, 9, 5, 4, 6, 4, 6, 8, 10, 5, 4, 6, 4, 6, 6, 4, 5, 7, 8, 7, 5, 4, 8, 4, 5, 10, 7]}",
    "scores = ${1:[/* your sample data here */]}",
    "n = len(scores)",
    "mu_0 = ${2:null_hypothesis_mean}  # hypothesized mean (H₀)",
    "alpha = ${3:0.05}  # significance level",
    "",
    "# --- Sample statistics ---",
    "m_sample = np.mean(scores)",
    "s = np.std(scores, ddof=1)        # Sample standard deviation (unknown population std)",
    "SE = s / math.sqrt(n)             # Standard error",
    "",
    "print(f\"Sample mean: {m_sample:.3f}\")",
    "",
    "# --- P-VALUE METHOD (Right-Tailed) ---",
    "p = stats.t.sf(m_sample, df=n-1, loc=mu_0, scale=SE)",
    "print(f\"p-value: {p:.5f}\")",
    "if p < alpha:",
    "    print(\"p < alpha: reject H₀\")",
    "else:",
    "    print(\"p ≥ alpha: do not reject H₀\")",
    "",
    "# --- CRITICAL VALUE METHOD ---",
    "g = stats.t.isf(alpha, df=n-1, loc=mu_0, scale=SE)",
    "print(f\"Critical value g ≃ {g:.3f}\")",
    "if m_sample < g:",
    "    print(f\"sample mean = {m_sample:.3f} < g = {g:.3f}: do not reject H₀\")",
    "else:",
    "    print(f\"sample mean = {m_sample:.3f} > g = {g:.3f}: reject H₀\")",
    "",
    "# --- PLOT THE t-DISTRIBUTION ---",
    "dist_x = np.linspace(mu_0 - 4 * s, mu_0 + 4 * s, 201)",
    "dist_y = stats.t.pdf(dist_x, df=n-1, loc=mu_0, scale=SE)",
    "fig, ax = plt.subplots()",
    "ax.plot(dist_x, dist_y, label='Sampling Distribution under $H_0$')",
    "",
    "# Hypothetical population mean line",
    "ax.axvline(mu_0, color='orange', lw=2, label='Null Mean (μ₀)')",
    "# Sample mean line",
    "ax.axvline(m_sample, color='red', linestyle='--', lw=2, label='Sample Mean (x̄)')",
    "",
    "# Shade acceptance region (right-tailed test: x < g)",
    "ax.fill_between(dist_x, 0, dist_y, where=(dist_x <= g), color='lightblue', alpha=0.5, label='Acceptance Region')",
    "",
    "# Labels, legend, and grid",
    "ax.set_title('Right-Tailed Student\\'s t-Test')",
    "ax.set_xlabel('Sample Mean')",
    "ax.set_ylabel('Probability Density')",
    "ax.legend()",
    "ax.grid(True)",
    "plt.show()"
  ],
  "description": "Right-tailed Student's t-test with p-value, critical value, and plot of sampling distribution with acceptance region shaded."
},
"Two-Tailed One-Sample t-Test with ttest_1samp": {
  "prefix": "ttest_1samp_template",
  "body": [
    "# --- Parameters ---",
    "data = ${1:[/* sample data goes here */]}",
    "mu = ${2:known_mean}  # Null hypothesis mean",
    "alpha = ${3:0.05}  # Significance level",
    "",
    "# --- Perform t-test ---",
    "t_stat, p_val = stats.ttest_1samp(a=data, popmean=mu${4:, alternative='two-sided'}) # of alternative='greater' or 'less' for one-tailed, denk ik",
    "",
    "print(f\"Sample mean       : {np.mean(data):.3f}\")",
    "print(f\"t-score           : {t_stat:.3f}\")",
    "print(f\"p-value           : {p_val:.5f}\")",
    "",
    "# --- Decision ---",
    "if p_val < alpha:",
    "    print(\"p < alpha: reject H₀\")",
    "else:",
    "    print(\"p ≥ alpha: do not reject H₀\")"
  ],
  "description": "Template for two-tailed one-sample t-test using scipy.stats.ttest_1samp"
},
"Sampling Distribution Visual & Area Analysis": {
  "prefix": "sample_dist",
  "body": [
    "# General parameters",
    "mu = ${1:population_mean}",
    "sigma = ${2:population_std_dev}",
    "n = ${3:sample_size}",
    "se = sigma / np.sqrt(n)  # Standard error",
    "",
    "# Generate x-values for the sampling distribution",
    "dist_x = np.linspace(mu - 4 * se, mu + 4 * se, num=201)",
    "dist_y = stats.norm.pdf(dist_x, mu, se)",
    "",
    "# Plot the normal curve",
    "plt.plot(dist_x, dist_y, label='Sampling Distribution of x̄')",
    "",
    "# Calculate and shade P(x̄ < value1)",
    "value1 = ${4:185}",
    "plt.fill_between(dist_x, 0, dist_y, where=(dist_x < value1), color='lightblue', label=f'x̄ < {value1}')",
    "plt.axvline(value1, color='green', linestyle='--')",
    "print(f\"P(x̄ < {value1}) = {stats.norm.cdf(value1, mu, se):.4f}\")",
    "",
    "# Calculate and shade P(value2 < x̄ < value3)",
    "value2 = ${5:175}",
    "value3 = ${6:185}",
    "plt.fill_between(dist_x, 0, dist_y, where=(dist_x >= value2) & (dist_x <= value3), color='orange', alpha=0.4, label=f'{value2} < x̄ < {value3}')",
    "print(f\"P({value2} < x̄ < {value3}) = {stats.norm.cdf(value3, mu, se) - stats.norm.cdf(value2, mu, se):.4f}\")",
    "",
    "# Calculate and shade P(x̄ > value4)",
    "value4 = ${7:190}",
    "plt.fill_between(dist_x, 0, dist_y, where=(dist_x > value4), color='red', alpha=0.3, label=f'x̄ > {value4}')",
    "plt.axvline(value4, color='red', linestyle='--')",
    "print(f\"P(x̄ > {value4}) = {stats.norm.sf(value4, mu, se)*100:.4f}\")",
    "",
    "# Labels and final plot",
    "plt.title('Sampling Distribution of Sample Mean')",
    "plt.xlabel('Sample Mean (x̄)')",
    "plt.ylabel('Probability Density')",
    "plt.grid(True)",
    "plt.legend()",
    "plt.show()"
  ],
  "description": "General-purpose sampling distribution plot with area analysis (left, between, right)"
},
"Sampling Distribution Z-Score Template": {
  "prefix": "sample_zscore_exact",
  "body": [
    "# --- Parameters ---",
    "n = ${1:20}               # sample size (number of observations)",
    "mu = ${2:population_mean} # population mean (average value in population)",
    "sigma = ${3:10}           # population standard deviation",
    "se = sigma / np.sqrt(n)   # standard error of the mean",
    "",
    "# --- Values to analyze ---",
    "x1 = ${4:45}              # first observed sample mean",
    "x2 = ${5:55}              # second observed sample mean",
    "",
    "# --- Probability range ---",
    "lower_bound = ${6:40}     # lower bound of interval",
    "upper_bound = ${7:60}     # upper bound of interval",
    "",
    "# --- Z-scores ---",
    "z1 = (x1 - mu) / se       # z-score for first sample mean",
    "z2 = (x2 - mu) / se       # z-score for second sample mean",
    "print(f\"Z-score for x̄ = {x1}: {z1:.2f}\")",
    "print(f\"Z-score for x̄ = {x2}: {z2:.2f}\")",
    "",
    "# --- Probability calculation ---",
    "prob_between = stats.norm.cdf(upper_bound, mu, se) - stats.norm.cdf(lower_bound, mu, se)",
    "print(f\"Probability that {lower_bound} < x̄ < {upper_bound}: {prob_between * 100:.2f}%\")",
    "",
    "# --- Plot the sampling distribution ---",
    "dist_x = np.linspace(mu - 4 * se, mu + 4 * se, num=201)",
    "dist_y = stats.norm.pdf(dist_x, mu, se)",
    "plt.plot(dist_x, dist_y)",
    "plt.axvline(x1, color='green', linestyle='--', label=f'x̄ = {x1}')",
    "plt.axvline(x2, color='red', linestyle='--', label=f'x̄ = {x2}')",
    "plt.fill_between(dist_x, 0, dist_y, where=(dist_x >= lower_bound) & (dist_x <= upper_bound), color='lightblue', label=f'{lower_bound} < x̄ < {upper_bound}')",
    "plt.title('Sampling Distribution of the Sample Mean')",
    "plt.xlabel('x̄')",
    "plt.ylabel('Probability Density')",
    "plt.legend()",
    "plt.grid(True)",
    "plt.show()"
  ],
  "description": "Template for analyzing sampling distribution, z-scores, and probabilities"
},
  "Chi-Square & Cramér’s V (Simple)": {
    "prefix": "chi_simple_cramer",
    "body": [
      "observed = pd.crosstab(${1:data}['${2:var1}'], ${1:data}['${3:var2}'])  # contingency table",
      "chi2, p, dof, expected = stats.chi2_contingency(observed)",
      "print(f\"Chi² statistic: {chi2:.3f}, p-value: {p:.3f}, dof: {dof}\")",
      "cramers_v = stats.contingency.association(observed, method='cramer')",
      "print(f\"Cramér’s V: {cramers_v:.3f}\")"
    ],
    "description": "Quick chi-square test and Cramér’s V"
  },
  "Independent Samples t-test (with p-value check)": {
    "prefix": "ttest2",
    "body": [
      "# === Sample Data ===",
      "group1 = np.array([${1:91, 87, 99, 77, 88, 91}])            # Control group (e.g., placebo)",
      "group2 = np.array([${2:101, 110, 103, 93, 99, 104}])         # Treatment group (e.g., new drug)",
      "",
      "# === Visualization ===",
      "sns.boxplot(data=pd.DataFrame({'Group 1': group1, 'Group 2': group2}), orient='h');",
      "",
      "# === t-test ===",
      "result = stats.ttest_ind(a=group1, b=group2,",
      "    alternative='${3:less}',  # 'less', 'greater', or 'two-sided'",
      "    equal_var=False)",
      "",
      "# === Output Results ===",
      "print('t-statistic: {:.4f}'.format(result.statistic))",
      "print('p-value    : {:.4f}'.format(result.pvalue))",
      "",
      "# === Decision Based on Significance Level ===",
      "alpha = ${4:0.05}  # Significance level",
      "if result.pvalue < alpha:",
      "    print(f'Result: Reject the null hypothesis (p < {alpha})')",
      "else:",
      "    print(f'Result: Do NOT reject the null hypothesis (p ≥ {alpha})')"
    ],
    "description": "Independent samples t-test with p-value interpretation"
  },
  "Paired Samples t-test (with p-value check)": {
  "prefix": "ttestpaired",
  "body": [
    "# === Sample Data ===",
    "before = np.array([${1:16, 20, 21, 22, 23, 22, 27, 25, 27, 28}])      # Before (e.g., regular fuel)",
    "after  = np.array([${2:19, 22, 24, 24, 25, 25, 26, 26, 28, 32}])      # After  (e.g., with additives)",
    "",
    "# === Visualization ===",
    "sns.boxplot(data=pd.DataFrame({'Before': before, 'After': after}), orient='h');",
    "",
    "# === Paired t-test ===",
    "result = stats.ttest_rel(before, after,",
    "    alternative='${3:less}')  # Options: 'two-sided', 'less', 'greater'",
    "# 'two-sided': tests if the means are different",
    "# 'less'     : tests if mean(before) < mean(after)",
    "# 'greater'  : tests if mean(before) > mean(after)",
    "",
    "# === Output ===",
    "print(f't-statistic : {result.statistic:.4f}')",
    "print(f'p-value     : {result.pvalue:.4f}')",
    "",
    "# === Decision Based on Significance Level ===",
    "alpha = ${4:0.05}  # Significance level",
    "if result.pvalue < alpha:",
    "    print(f'Result: Reject the null hypothesis (p < {alpha})')",
    "else:",
    "    print(f'Result: Do NOT reject the null hypothesis (p ≥ {alpha})')"
  ],
  "description": "Paired t-test with interpretation and visualisation"
},
  "Cohen's d Effect Size (Independent Samples)": {
    "prefix": "cohend",
    "body": [
      "# === Sample Data ===",
      "group1 = np.array([${1:16, 20, 21, 22, 23, 22, 27, 25, 27, 28}])  # e.g., regular gasoline",
      "group2 = np.array([${2:19, 22, 24, 24, 25, 25, 26, 26, 28, 32}])  # e.g., gasoline with additives",
      "",
      "# === Cohen's d Function ===",
      "def cohen_d(a, b):",
      "    na = len(a)",
      "    nb = len(b)",
      "    # Pooled standard deviation",
      "    pooled_sd = np.sqrt(((na - 1) * np.var(a, ddof=1) + (nb - 1) * np.var(b, ddof=1)) / (na + nb - 2))",
      "    return (np.mean(b) - np.mean(a)) / pooled_sd",
      "",
      "# === Compute Effect Size ===",
      "d = cohen_d(group1, group2)",
      "print(f\"Cohen's d: {d:.4f}\")",
      "",
      "# === Interpretation ===",
      "if d < 0.01:",
      "    print('Interpretation: Negligible effect size')",
      "elif d < 0.2:",
      "    print('Interpretation: Very small effect size')",
      "elif d < 0.5:",
      "    print('Interpretation: Small effect size')",
      "elif d < 0.8:",
      "    print('Interpretation: Medium effect size')",
      "else:",
      "    print('Interpretation: Large effect size')",
      "",
      "# Research reference: In education, d ≥ 0.4 is considered meaningful (Hattie, 2012)"
    ],
    "description": "Calculate Cohen's d for independent samples and interpret the effect size"
  },
  "Seaborn Relplot (Scatter)": {
    "prefix": "relplot",
    "body": [
      "# Scatter plot using Seaborn relplot",
      "sns.relplot(",
      "    data=${1:dataframe},",
      "    x='${2:independent_variable}',",
      "    y='${3:dependent_variable}',",
      "    kind='scatter',",
      "    hue='${4:grouping_variable}',  # optional: remove or edit if not needed, exaple is species for colour",
      "    height=${5:5},",
      "    aspect=${6:1.2}",
      "    style='${7:style_variable}' # add other variables ads needed like size",
      ");"
    ],
    "description": "Seaborn relplot scatter template (x=independent, y=dependent, generic data)"
  },
  "Linear Regression with sklearn": {
    "prefix": "linreg",
    "body": [
      "# Assume you have a DataFrame 'df' and columns 'X_col' and 'Y_col' for features and target",
      "X = df['X_col'].values.reshape(-1, 1)  # explanatory variable (independent) - converts array from 1D to 2D, necessary for this",
      "y = df['Y_col']  # dependent variable",
      "",
      "# Fit linear regression model",
      "model = LinearRegression().fit(X, y)",
      "",
      "intercept = model.intercept_",
      "slope = model.coef_[0]",
      "print(f\"Regression line: ŷ = {intercept:.4f} + {slope:.4f} x\")",
      "",
      "# Interpret slope",
      "if slope > 0:",
      "    print(f\"The slope is positive ({slope:.4f}), indicating that as X increases, Y tends to increase.\")",
      "elif slope < 0:",
      "    print(f\"The slope is negative ({slope:.4f}), indicating that as X increases, Y tends to decrease.\")",
      "else:",
      "    print(\"The slope is zero, indicating no linear relationship between X and Y.\")",
      "",
      "# Visualize data and regression line",
      "sns.lmplot(data=df, x='X_col', y='Y_col');"
    ],
      "description": "Fit a simple linear regression with sklearn and print the regression line"
    },
    "Calculate Covariance (manual and numpy)": {
    "prefix": "covariance-manual",
    "body": [
      "import numpy as np",
      "",
      "# Your data arrays for X and Y",
      "X = np.array([$1])",
      "Y = np.array([$2])",
      "",
      "# Means",
      "mean_x = np.mean(X)",
      "mean_y = np.mean(Y)",
      "",
      "# Manual covariance calculation",
      "cov_manual = np.sum((X - mean_x) * (Y - mean_y)) / (len(X) - 1)",
      "print(f\"Manual covariance: {cov_manual:.4f}\")",
      "",
      "# Covariance using numpy.cov (returns covariance matrix)",
      "cov_matrix = np.cov(X, Y, ddof=1)",
      "cov_numpy = cov_matrix[0, 1]",
      "print(f\"Covariance from np.cov: {cov_numpy:.4f}\")",
      "",
      "# Interpretation",
      "if cov_manual > 0:",
      "    print(\"Covariance is positive: variables tend to increase together.\")",
      "elif cov_manual < 0:",
      "    print(\"Covariance is negative: variables tend to move in opposite directions.\")",
      "else:",
      "    print(\"Covariance is near zero: no clear linear relationship.\")"
    ],
    "description": "Calculate covariance manually and with numpy, then interpret the result"
  },
  "Covariance Plot and Interpretation": {
    "prefix": "covplot",
    "body": [
      "# Replace these with your actual data arrays",
      "X = np.array([${1:# e.g. 1, 2, 3, 4, 5}])",
      "Y = np.array([${2:# e.g. 2, 3, 5, 7, 11}])",
      "",
      "# Calculate covariance and variance using numpy",
      "cov_matrix = np.cov(X, Y, ddof=1)",
      "cov = cov_matrix[0, 1]",
      "var_x = cov_matrix[0, 0]",
      "print(f\"Covariance between X and Y: {cov:.4f}\")",
      "",
      "# Interpretation",
      "if cov > 0:",
      "    print(\"Covariance is positive: variables tend to increase together.\")",
      "elif cov < 0:",
      "    print(\"Covariance is negative: variables tend to move in opposite directions.\")",
      "else:",
      "    print(\"Covariance is near zero: no clear linear relationship.\")",
      "",
      "# Regression coefficients (slope and intercept)",
      "beta1 = cov / var_x",
      "beta0 = np.mean(Y) - beta1 * np.mean(X)",
      "print(f\"Regression line: ŷ = {beta0:.4f} + {beta1:.4f} x\")",
      "",
      "# Plotting",
      "xmin, xmax = min(X), max(X)",
      "ymin, ymax = min(Y), max(Y)",
      "mean_x = np.mean(X)",
      "mean_y = np.mean(Y)",
      "",
      "plt.figure(figsize=(8, 6))",
      "sns.scatterplot(x=X, y=Y)",
      "",
      "# Plot means as dashed green lines",
      "plt.axvline(mean_x, color='g', linestyle='dashed', linewidth=1)",
      "plt.axhline(mean_y, color='g', linestyle='dashed', linewidth=1)",
      "",
      "# Draw the regression line through two points at xmin and xmax",
      "plt.plot([xmin, xmax], [beta0 + beta1 * xmin, beta0 + beta1 * xmax], color='r')",
      "",
      "# Add quadrant labels",
      "plt.text(xmin + (xmax - xmin) * 0.85, ymin + (ymax - ymin) * 0.8, \"I\", backgroundcolor=\"bisque\", fontsize=\"large\")",
      "plt.text(xmin + (xmax - xmin) * 0.15, ymin + (ymax - ymin) * 0.2, \"II\", backgroundcolor=\"bisque\", fontsize=\"large\")",
      "plt.text(xmin + (xmax - xmin) * 0.15, ymin + (ymax - ymin) * 0.8, \"III\", backgroundcolor=\"bisque\", fontsize=\"large\")",
      "plt.text(xmin + (xmax - xmin) * 0.85, ymin + (ymax - ymin) * 0.2, \"IV\", backgroundcolor=\"bisque\", fontsize=\"large\")",
      "",
      "plt.xlabel(\"X\")",
      "plt.ylabel(\"Y\")",
      "plt.title(\"Scatterplot with Means, Regression Line, and Covariance Quadrants\")",
      "plt.show()"
    ],
    "description": "Calculate covariance between two variables, plot scatterplot with means and quadrant labels, and interpret covariance value."
  },
  "Correlation from Covariance and Std Dev": {
    "prefix": "correlation",
    "body": [
        "# Replace these with your actual data arrays",
        "X = np.array([${1:# e.g. 1, 2, 3, 4, 5}])",
        "Y = np.array([${2:# e.g. 2, 3, 5, 7, 11}])",
        "",
        "# Calculate covariance matrix and covariance",
        "cov_matrix = np.cov(X, Y, ddof=1)",
        "cov = cov_matrix[0, 1]",
        "print(f\"Covariance between X and Y: {cov:.4f}\")",
        "",
        "# Calculate standard deviations",
        "std_x = np.std(X, ddof=1)",
        "std_y = np.std(Y, ddof=1)",
        "",
        "# Calculate correlation manually from covariance and std dev",
        "R1 = cov / (std_x * std_y)",
        "print(f\"Correlation (from covariance and std dev): R ≈ {cov:.4f} / ({std_x:.4f} * {std_y:.4f}) = {R1:.4f}\")",
        "",
        "# Calculate correlation using the elaborated formula",
        "xx = X - np.mean(X)",
        "yy = Y - np.mean(Y)",
        "R2 = np.sum(xx * yy) / np.sqrt(np.sum(xx ** 2) * np.sum(yy ** 2))",
        "print(f\"Correlation (from formula): R ≈ {R2:.4f}\")",
        "",
        "# Calculate correlation using numpy's corrcoef",
        "cor_matrix = np.corrcoef(X, Y)",
        "cor = cor_matrix[0, 1]",
        "print(f\"Correlation (numpy.corrcoef): R ≈ {cor:.4f}\")",
        "",
        "# Interpretation",
        "if cor > 0:",
        "    print(\"Positive correlation: as X increases, Y tends to increase.\")",
        "elif cor < 0:",
        "    print(\"Negative correlation: as X increases, Y tends to decrease.\")",
        "else:",
        "    print(\"No linear correlation detected.\")"
    ],
    "description": "Calculate correlation coefficient R from covariance and standard deviations with multiple methods and interpret the result."
  },
    "Correlation and Coefficient of Determination (R and R2)": {
    "prefix": "r2analysis",
    "body": [
      "# Replace these with your actual data arrays",
      "X = np.array([${1:# e.g. 1, 2, 3, 4, 5}])",
      "Y = np.array([${2:# e.g. 2, 4, 5, 4, 5}])",
      "",
      "# Pearson correlation coefficient (R)",
      "cov_matrix = np.cov(X, Y, ddof=1)",
      "cov = cov_matrix[0, 1]",
      "std_x = np.std(X, ddof=1)",
      "std_y = np.std(Y, ddof=1)",
      "R = cov / (std_x * std_y)",
      "print(f\"Pearson's R ≈ {R:.4f}\")",
      "",
      "# Coefficient of determination (R²)",
      "R2 = R ** 2",
      "print(f\"R² ≈ {R2:.4f} → About {R2 * 100:.1f}% of the variation in Y is explained by X\")",
      "",
      "# Linear Regression fit to get R² automatically",
      "X_reshaped = X.reshape(-1, 1)",
      "model = LinearRegression().fit(X_reshaped, Y)",
      "model_r2 = model.score(X_reshaped, Y)",
      "print(f\"R² from LinearRegression.score(): {model_r2:.4f}\")",
      "",
      "# Interpretation based on R² value",
      "abs_r = abs(R)",
      "if abs_r < 0.3:",
      "    strength = \"very weak\"",
      "elif abs_r < 0.5:",
      "    strength = \"weak\"",
      "elif abs_r < 0.7:",
      "    strength = \"moderate\"",
      "elif abs_r < 0.85:",
      "    strength = \"strong\"",
      "elif abs_r < 0.95:",
      "    strength = \"very strong\"",
      "else:",
      "    strength = \"exceptionally strong\"",
      "",
      "direction = \"increasing\" if R > 0 else \"decreasing\" if R < 0 else \"no direction\"",
      "print(f\"The relationship is {direction} and {strength}.\")"
    ],
    "description": "Calculate Pearson correlation (R), coefficient of determination (R²), and interpret the strength of the linear relationship."
  }
}


